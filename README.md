# [TECH CHALLENGE IADT] Sistema de Suporte ao Diagn√≥stico de C√¢ncer de Mama

## üí° Descri√ß√£o do Projeto
Este projeto implementa uma solu√ß√£o de Machine Learning (Decision Tree e Random Forest) treinada em dados balanceados e escalonados para auxiliar m√©dicos na an√°lise inicial de exames de c√¢ncer de mama. O sistema utiliza um modelo de classifica√ß√£o para prever a probabilidade de um tumor ser maligno ou benigno. O deploy √© feito via Streamlit, oferecendo uma interface intuitiva para uso cl√≠nico.

---

## üíæ Dataset e Fonte de Dados
O projeto utiliza o conjunto de dados de diagn√≥stico de c√¢ncer de mama (Wisconsin Breast Cancer) para modelagem.

**Link para Download:** [https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data/data]

---

## üíª Estrutura do Reposit√≥rio

| Arquivo/Pasta | Fun√ß√£o |
| :--- | :--- |
| `deploy.py` | C√≥digo-fonte do aplicativo Streamlit (a interface de usu√°rio). |
| `algoritmo_aplicado.py` | Script de treinamento, balanceamento e valida√ß√£o dos modelos (Decision Tree e Random Forest). |
| `analise_exploratoria.py` | Script para EDA, visualiza√ß√£o de correla√ß√µes e an√°lise bivariada. |
| `decision_tree_model.joblib` | **Modelo de Decision Tree** treinado, salvo para uso no deploy. |
| `minmax_scaler.joblib` | Objeto **MinMaxScaler** treinado, salvo para pr√©-processar dados de entrada. |
| `requirements.txt` | Lista de todas as bibliotecas Python necess√°rias. |
| `Dockerfile` | Receita para construir o container Docker, garantindo a reprodutibilidade. |

---

## ‚öôÔ∏è Instru√ß√µes de Execu√ß√£o (via Docker)

Para rodar o aplicativo de forma isolada e sem instalar depend√™ncias locais, siga os passos abaixo:

### Pr√©-requisito
Voc√™ precisa ter o **Docker** instalado e funcionando em sua m√°quina.

### Passo 1: Clonar o Reposit√≥rio
```bash
git clone [INSIRA A URL DO SEU REPOSIT√ìRIO AQUI]
cd [NOME_DO_SEU_REPOSITORIO]

### Passo 2: Construir a Imagem Docker
docker build -t suporte-diagnostico .

### Passo 3: Rodar o Container
docker run -p 8501:8501 suporte-diagnostico

üî¨ Resultados Obtidos e Relat√≥rio
1. Estrat√©gias de Pr√©-processamento
Sele√ß√£o de Features: Foquei  em 8 features principais (Radius_mean,Perimeter_mean,Area_mean,Radius_worst,Perimeter_worst,Area_worst,Area_se e Texture_worst.) para reduzir a multicolinearidade e simplificar o modelo, mantendo o poder preditivo.
Observa√ß√£o: Para a escolha dessas colunas foi feita uma an√°lise usando Mapa de calor e Box Plot.  

Balanceamento de Classes: Indentifiquei um  o desequil√≠brio na base de treino e apliquei  o RandomOverSampler (imblearn) apenas nos dados de treino para equalizar o n√∫mero de casos Malignos e Benignos e eliminar o vi√©s, evitando que o modelo visse apenas muitos dados de uma determina classe e pouco de outra.

Escalonamento: O MinMaxScaler foi usado para normalizar as features, garantindo que o modelo Decision Tree as trate com pesos iguais.

2. Modelos Usados e Justificativa
Modelo: Decision Tree Classifier
Justificativa: Ofereceu um excelente equil√≠brio entre Precis√£o e Recall e, crucialmente, alta Interpretabilidade (Feature Importance). Foi o modelo escolhido para o deploy.

Modelo:Random Forest Classifier
Justificativa: Ofereceu um excelente equil√≠brio entre Precis√£o e Recall e, crucialmente, alta Interpretabilidade, por√©m o tempo de processamento foi elevado, fazendo com que ele fosse descartado para a etapa do deploy.

üî¨ 3. M√©tricas e An√°lise de Desempenho
Modelo DECISION TREE CLASSIFIER
A. Feature Importance (Import√¢ncia das Features)
O Feature Importance √© uma t√©cnica que mostra quais caracter√≠sticas do tumor foram mais decisivas na tomada de decis√£o do modelo.

Feature	Valor de Import√¢ncia
perimeter_worst	0.751879
texture_worst	0.097178
area_mean	0.052566
area_worst	0.032957
radius_mean	0.022843
area_se	0.021878
radius_worst	0.016609
perimeter_mean	0.004091

Interpreta√ß√£o: A caracter√≠stica perimeter_worst (per√≠metro do tumor no pior caso) √©, de longe, o fator mais importante para a decis√£o do modelo (respons√°vel por mais de 75% da import√¢ncia total). Isso justifica a sele√ß√£o dessa feature, provando que ela √© a principal preditora do diagn√≥stico.

B. Relat√≥rio de Classifica√ß√£o (Decision Tree)
Classe	Precision	Recall	F1-Score	Support
Benigno (0)	0.92	0.90	0.91	61
Maligno (1)	0.88	0.90	0.89	51
Accuracy (Total)			0.90	112

Explica√ß√£o das M√©tricas:

Precision (Precis√£o): De todas as vezes que o modelo previu Maligno, ele acertou 88% delas.

Recall (Sensibilidade): De todos os casos Malignos que realmente existiam, o modelo identificou corretamente 90% deles. Em um diagn√≥stico m√©dico, o Recall alto √© crucial para evitar Falsos Negativos (ignorar um c√¢ncer).

F1-Score: √â a m√©dia harm√¥nica entre Precision e Recall. Um F1-Score de 0.89 para a classe Maligna indica um desempenho geral muito forte.

Accuracy (Acur√°cia): O modelo acertou o diagn√≥stico em 90% das vezes.

C. Matriz de Confus√£o (Decision Tree)
Previs√£o: Benigno	Previs√£o: Maligno	Total Real
Benigno	55 (Verdadeiros Negativos)	6 (Falsos Positivos)	61
Maligno	5 (Falsos Negativos)	46 (Verdadeiros Positivos)	51
Total Previsto	60	52	112

Explica√ß√£o: A matriz de confus√£o visualiza a performance. O resultado mais importante √© a baixa incid√™ncia de Falsos Negativos (casos reais de c√¢ncer que o modelo classificou como benignos). O modelo Decision Tree demonstra seguran√ßa ao manter esse erro cr√≠tico em um n√≠vel baixo.

Modelo de Compara√ß√£o: RANDOM FOREST CLASSIFIER
O Random Forest foi usado para validar se um modelo mais complexo traria ganhos significativos.

Relat√≥rio de Classifica√ß√£o (Random Forest)
Classe	Precision	Recall	F1-Score	Support
Benigno (0)	0.88	0.95	0.91	61
Maligno (1)	0.93	0.84	0.89	51
Accuracy (Total)			0.90	112

Matriz de Confus√£o (Random Forest)
Previs√£o: Benigno	Previs√£o: Maligno	Total Real
Benigno	58 (Verdadeiros Negativos)	3 (Falsos Positivos)	61
Maligno	8 (Falsos Negativos)	43 (Verdadeiros Positivos)	51
Total Previsto	66	46	112

Conclus√£o: O Random Forest teve uma Precision ligeiramente maior para a classe Maligna (0.93 vs. 0.88), mas um Recall pior (0.84 vs. 0.90). Como o Recall (identificar o c√¢ncer real) √© mais importante em um diagn√≥stico, a Decision Tree √© o modelo mais adequado e seguro para o deploy, apesar da complexidade do Random Forest.




